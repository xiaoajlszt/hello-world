第一章 HTTP概述
1.3 资源
1. MIME
HTTP给每种需要通过Web传输的对象都打上了名为MIME(Multipurpose Internet Mail Extension,多用途因特网邮件扩展)类型的数据格式标签，用来描述并标记多媒体内容。
<1>Web服务器会为所有HTTP对象数据附加一个MIME类型。当浏览器从服务器中取回一个对象时，会去查看相关的MIME类型，看看它是否知道应该如何处理这个对象。
- eg: Content-type: image/jpeg		

<2>MIME类型是一种文本标记，表示一种主要的对象类型和一个特定的子类型，中间由一条斜杠分隔。
- HTML格式的文本文档	text/html
- 普通的ASCII文本文档	text/plain
- JPEG版本的图片		image/jpeg
- GIF格式的图片			image/gif
。。。

2. URI(Uniform Resource Identifier,统一资源标识符)
URI有两种形式，分别称为URL和URN。

<1>URL(统一资源限定符)
它是资源标识符中最常见的，描述了一台特定服务器上某资源的特定位置。几乎所有的URI都是URL。

大部分URL都遵循一种标准格式，包括三部分：
http://www.joes-hardware.com/specials/saw-blade.gif
- scheme 说明了访问资源所使用的协议类型。	http://
- 服务器的因特网地址						www.joes-hardware.com
- 指定服务器上的某个资源					/specials/saw-blade.gif

<2>URN(统一资源名)
- 作为特定内容的唯一名称使用的，与资源所在地无关，这样可以将资源四处搬移。
- URN仍处于实验阶段，还未大范围使用。

1.4 事务
一个HTTP事务由一条请求命令和一个响应结果组成。这种通讯是通过名为HTTP报文的格式化数据块进行的。

<1>方法
- GET		从服务器向客户端发送命名资源
- PUT		将来自客户端的数据存储到一个命名的服务器资源中去
- DELETE	从服务器中删除命名资源
- POST		将客户端数据发送到一个服务器网关应用程序
- HEAD		仅发送命名资源响应中的HTTP首部

<2> 状态码
每条HTTP响应报文返回时都会携带一个状态码。状态码是一个三位数字的代码，告知客户端请求是否成功，或者是否需要采取其他动作。
- 200		ok
- 302		Redirect(重定向)，到其他地方去获取资源
- 400       Unauthorized(未授权)，需要输入用户名和密码
- 404		Not Found，无法找到这个资源

//伴随着每个数字状态码，HTTP还会发送一条解释性的"原因短语"文本。包含文本短语主要是为了进行描述，所有的处理过程使用的都是数字码。

1.5 报文
<1>HTTP报文是由一行行的简单字符串组成的。
- HTTP报文都是纯文本

<2>HTTP报文包括三个部分：
1) 起始行。报文的第一行，在请求报文中说明要做什么；在响应报文中说明出现了什么情况。
2) 首部字段。起始行后面有零个或多个首部字段。每个首部字段都包含一个名字和一个值，两者之间用冒号分隔。首部以一个空行结束。
3) 主体。空行之后就是可选的报文主体，其中包含了所有类型的数据。
//起始行和首部字段都是文本形式且都是结构化的；而主体中可以包含任意的二进制数据和文本。

1.8 Web的结构组件
<1>代理proxy - 位于客户端和服务器之间的HTTP中间实体。
HTTP代理服务器是Web安全、应用集成以及性能优化的重要组成模块。
- 代理位于客户端和服务器之间，接收所有客户端的HTTP请求，并将这些请求转发给服务器。
//对于用户来说，这些应用程序就是一个代理，代表用户访问服务器。
- 出于安全考虑，通常会将代理作为转发所有Web流量的可信任中间节点使用。
- 代理还可以对请求和响应进行过滤。

<2>缓存cache - HTTP的仓库，使常用页面的副本可以保存在离客户端更近的地方。
Web缓存或代理缓存是一种特殊的HTTP代理服务器，可以将经过代理传送的常用文档复制保存起来。
下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。

<3>网关gateway - 连接其他应用程序的特殊Web服务器。
网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将HTTP流量转换成其他协议。

<4>隧道tunnel - 对HTTP通信报文进行盲转发的特殊代理。
隧道是建立起来之后，就会在两条连接之间对原始数据进行盲转发的HTTP应用程序。
HTTP隧道通常用来在一条或多条HTTP连接上转发非HTTP数据，转发时不会窥探数据。
//HTTP隧道的一种常见用途是通过HTTP连接承载加密的SSL流量，这样SSL流量就可以穿过只允许Web流量通过的防火墙了。

<5>Agent代理 - 发起自动HTTP请求的半智能Web客户端。
用户Agent代理是代表用户发起HTTP请求的客户端程序。所有发布web请求的应用程序都是HTTP Web代理。
//Web浏览器、网络蜘蛛、Web机器人

---------------------------------------------------------------------------
其他：
HTTP和SOAP
https://www.cnblogs.com/leijiangtao/p/5137351.html
---------------------------------------------------------------------------

第三章 HTTP报文
3.1 报文流
1. 报文流入源端服务器
HTTP使用术语流入(inbound)和流出(outbound)来描述事务处理的方向。报文流入源端服务器，工作完成后会流回用户的Agent代理中。

2. 报文向下游流动
所有报文的发送者都在接收者的上游(upstream)，所有报文都会向下游(downstream)流动。

3.2 报文的组成部分
起始行(start line)
首部(header)
主体(body)

- 起始行和首部就是由行分隔的ASCII文本，每行都以一个由两个字符(回车&换行 CRLF)组成的行终止序列作为结束。
//稳健的应用程序也应该接受单个换行符作为行的终止。
- 主体是一个可选的数据块。与起始行和首部不同，主体中可以包含文本或二进制数据，也可以为空。

1. 报文的语法

2. 起始行
<1>请求行 - 请求报文的起始行
<method> <request-URL> <version>

<2>响应行 - 响应报文的起始行
<version> <status> <reason-phrase>

<3>方法
- GET		从服务器获取一份文档								不包含主体
- HEAD  	只从服务器获取文档的首部							不包含主体
- POST  	向服务器发送需要处理的数据							包含主体
- PUT   	将请求的主体部分存储在服务器上  					包含主体
- TRACE 	对可能经过代理服务器传送到服务器上的报文进行追踪	不包含主体
- OPTIONS	决定可以在服务器上执行哪些方法						不包含主体
- DELETE	从服务器上删除一份文档								不包含主体

//由于HTTP设计得易于扩展，所以除了这些方法之外，其他服务器可能还会实现一些自己的请求方法。称为扩展方法。

<4>状态码
			已分配
100-199		100-101		信息提示
200-299		200-206		成功
300-399		300-305		重定向
400-499		400-415		客户端错误
500-599		500-505		服务器错误

<5>原因短语

<6>版本号
HTTP/x.y
//2.22 > 2.3

3. 首部
跟在起始行后面的零个、一个或多个HTTP首部字段。

<1>HTTP规范定义了几种首部字段，应用程序也可以随意发明自己所用的首部。
- 通用首部 //既可以出现在请求报文中，也可以出现在响应报文中
- 请求首部
- 响应首部
- 实体首部 //描述主体的长度和内容，或者资源自身
- 扩展首部

<2>首部延续行
将长的首部行分为多行可以提高可读性，多出来的每行前面至少有一个空格或制表符Tab。
Server: Test Server
	Version 1.0

4. 实体的主体部分

3.3 方法
<1>并不是每个服务器都实现了所有的方法。如果一台服务器要与HTTP/1.1兼容，只要为其资源实现GET和HEAD方法即可。

<2>即使服务器实现了所有这些方法，方法的使用很可能也是受限制的。
//例如支持DELETE和PUT方法的服务器可能并不希望任何人都能够删除或存储资源。
这些限制通常都是在服务器的配置中进行设置的。

1. 安全方法
<1>HTTP定义了一组安全方法：使用这些方法的HTTP请求不会产生什么动作。意味着HTTP请求不会在服务器上产生什么结果。
GET HEAD

<2>安全方法并不一定是什么动作都不执行的(这是由Web开发者决定的)，使用安全方法的目的就是允许HTTP应用程序开发者通知用户，什么时候会使用某个可能引发某些动作的不安全方法。

2. GET - 请求服务器的某个资源。

3. HEAD - 与GET方法行为很类似，但服务器在响应中只返回首部，不返回实际的主体部分。
<1>允许客户端在未获取实际资源的情况下，对资源的首部进行检查。
- 在不获取资源的情况下了解资源的情况
- 通过查看响应中的状态码，看看某个对象是否存在
- 通过查看首部，测试资源是否被修改了

<2>服务器开发者必须确保返回的首部与GET请求所返回的首部完全相同。

3. PUT - 向服务器写入文档
<1>有些系统允许用户创建Web页面，并用PUT直接将其安装到Web服务器上去。

<2>PUT方法的语义就是让服务器用请求的主体部分来创建一个由所请求的URL命名的新文档。
如果那个URL已经存在，就用这个主体来替代它。

5. POST
POST方法起初是用来向服务器输入数据的，实际上，通常会用它来支持HTML的表单。
表单中填好的数据通常会被送给服务器，然后由服务器将其发送到它要去的地方。

<1>POST用于向服务器发送数据；PUT用于向服务器上的资源中存储数据。

6. TRACE
客户端发起一个请求时，这个请求可能要穿过防火墙、代理、网关或其他一些应用程序。
- 每个中间节点都可能修改原始的HTTP请求。
TRACE方法允许客户端在最终将请求发送给服务器时，看看它变成了什么样子。

<1>TRACE请求会在目的服务器端发起一个“环回”诊断。行程最后一站的服务器会弹回一条TRACE响应，并在响应主体中携带它收到的原始请求报文。

<2>尽管TRACE可以很方便地用于诊断，但它也有缺点。
- TRACE假定中间应用程序对各种不同类型请求(GET、HEAD、POST等)的处理是相同的。
- 很多HTTP应用程序会根据方法的不同做出不同的事情，比如：代理可能会将POST请求直接发送给服务器，而将GET请求发送给另一个HTTP应用程序(如Web缓存)。
- TRACE并不提供区分这些方法的机制。通常，中间应用程序会自行决定对TRACE请求的处理方式。

<3>TRACE的请求中不能带有实体的主体部分。TRACE的响应实体主体部分包含了响应服务器收到的请求的精确副本。

7. OPTIONS - 请求Web服务器告知其支持的各种功能
<1>可以询问服务器通常支持哪些方法，或者对某些特殊资源支持哪些方法。
//有些服务器可能只支持对一些特殊类型的对象使用特定的操作。

<2>这为客户端应用程序提供了一种手段，使其不用实际访问那些资源就能够判定访问各种资源的最优方式。

8. DELETE - 让服务器删除请求URL所指定的资源
<1>客户端应用程序无法保证删除操作一定会被执行，HTTP规范允许服务器在不通知客户端的情况下撤销请求。
//即使客户端收到了服务器返回的接受删除操作的响应。

9. 扩展方法
扩展方法就是指没有在HTTP/1.1规范中定义的方法。
- 服务器会为它所管理的资源实现一些HTTP服务，这些方法为开发者提供了一种扩展这些HTTP服务能力的手段。

<1>常见的扩展方法实例 - WebDAV HTTP扩展
LOCK	允许用户锁定资源，防止别人同时对其进行修改
MKCOL	允许用户创建资源
COPY    便于在服务器上复制资源
MOVE    在服务上移动资源

<2>并不是所有的扩展方法都是在正式规范中定义的，你定义的扩展方法，很可能大部分HTTP应用程序并不理解。
//在这种情况下，最好对扩展方法宽容一些。如果能够在不破坏端到端行为的情况下将带有未知方法的报文传递给下游服务器的话，代理会尝试传递这些报文。否则，它们会议501(无法实现)状态码进行响应。
//按“对所发送的内容要严格一些，对所接收的内容要宽容一些”的惯例来处理扩展方法。

3.4 状态码


3.5 首部



第14章 安全HTTP
14.1 保护HTTP的安全
1. HTTPS
HTTPS是最流行的HTTP安全形式，URL以https://开头，据此就可以分辨某个Web页面是通过HTTPS而不是HTTP访问的。

<1>使用HTTPS时，所有HTTP请求和响应数据在发送到网络之前，都要进行加密。
HTTPS在HTTP下面提供了一个传输级的密码安全层(可以使用SSL，也可以使用其后继者TLS -- Transport Layer Security)。
//由于SSL和TLS非常类似，本书用SSL表示SSL和TLS。

<2>大部分编解码工作都是在SSL库中完成的。
Web客户端和服务器在使用安全HTTP时无需过多地修改其协议处理逻辑，只需要用SSL的输入/输出调用取代TCP的调用，再增加其他几个调用来配置和管理安全信息就可以了。

14.2 数字加密
密码 - 对文本进行编码，使偷窥者无法识别的算法
密钥 - 改变密码行为的数字化参数
对称密钥加密系统 - 编/解码使用相同密钥的算法
不对称密钥加密系统 - 编/解码使用不同的密钥算法
公开密钥加密系统 - 一种能够使数百万计算机便捷地发送机密报文的系统
数字签名 - 用来验证报文未被伪造或篡改的校验和
数字证书 - 由一个可信的组织验证和签发的识别信息

1. 密码编制的机制和技巧
- 加密报文防止偷窥
- 防止对报文进行篡改
- 证明某条报文或某个事务确实出自你手

2. 密码(cipher)
密码是一套编码方案：一种特殊的报文编码方式和一种稍后使用的相应解码方式的结合体。
<1>加密之前的原始报文称为明文(plaintext或cleartext)
<2>加密之后的报文称为密文(ciphertext)

3. 密码机

4. 使用密钥的密码
编码算法和编码机都可能会落入敌手，所以大部分机器上都有一些号盘，可以将其设置为大量不同的值以改变密码的工作方式。即使机器被盗，没有正确的号盘设置(密钥值)，解码器也无法工作。

eg: 加密算法就是普通的"旋转-N字符"密码，N由密钥控制。

<1>这些密码参数被称为密钥(key)
<2>要在密码机中输入正确的密钥，解密过程才能正确进行。
密码密钥会让一个密码机看起来好像有多个虚拟密码机一样，每个密码机都有不同的密钥值，因此其行为都会有所不同。

5. 数字密码
这些数字密钥值是编/解码算法的输入。编/解码算法就是一些函数，这些函数会读取一块数据，并根据算法和密钥值对其进行编解/码。

14.3 对称密钥加密技术
很多数字加密算法都被称为对称密钥(symmetric-key)加密技术，是因为它们在编解码时使用相同的密钥。
流行的对称密钥加密算法包括：DES、Triple-DES、RC2、RC4。

1. 密钥长度与枚举攻击
很多情况下，编解码算法都是众所周知的，因此密钥就是唯一保密的东西了。

<1>好的加密算法会迫使攻击者试遍每一种可能的密钥，才能破解代码。
用暴力去尝试所有的密钥值称为枚举攻击。

<2>可用密钥值的数量取决于密钥中的位数，以及可能的密钥中有多少是有效的。
//就对称密钥加密技术来说，通常所有的密钥值都是有效的。
//40位的DES密钥是不安全的，通常认为长度与Triple-DES密钥相当的128位的密钥实际上是任何人以任何代价都无法通过暴力攻击破解的。

2. 建立共享密钥
对称密钥机密技术的缺点之一就是发送者和接收者在对话之前，一定要有一个共享的保密密钥。
//需要一种产生保密密钥并将其记住的方式。
//如果有N和节点，每个节点都要和其他节点进行安全对话，总共会有N^2个保密密钥，这将是一个管理噩梦。

14.4 公开密钥加密技术
<1>公开秘钥加密技术没有为每对主机使用单独的加密/解密密钥，而是使用了两个非对称密钥：一个用来对主机报文编码，另一个用来对主机报文解码。
- 编码密钥是众所周知的(这也是公开密钥加密名称的由来)
- 但只有主机知道私有的解密密钥(私钥)
这样每个人都能找到某个特定主机的公开密钥，密钥的建立变得更加简单。
但解码密钥是保密的，因此只有接收端才能对发送给它的报文进行解码。

<2>因为每台主机都分配了一个所有人均可以使用的编码密钥，所以公开密钥加密技术避免了对称密钥加密技术中对密钥数目的N^2扩展问题。 

<3>各节点向服务器安全发送报文更加容易。
通过公开密钥加密技术，全球所有的计算机用户就可以使用安全协议了。因此，大规模的公开密钥架构(PKI)标准创建工作已经开展十多年了。

1. RSA
即使拥有公共密钥、任意一段明文、用公共密钥对明文编码之后得到的相应密文、RSA算法自身、甚至是RSA实现的源代码，破解代码找到相应的私有密钥的难度仍相当于对一个极大的数进行质因数分解的困难程度。
//在RSA加密系统中，以任意顺序应用解码函数D和编码函数E，两者都会相互抵消。
E(D(stuff))=stuff
D(E(stuff))=stuff

2. 混合加密系统和会话密钥
非对称的公开密钥加密系统，两节点无需为了进行安全通信而先交换私有密钥。但公开密钥加密算法可能会很慢。
比较常见的做法是在两节点间通过便捷的公开密钥加密技术建立起安全通信，然后再用那条安全的通道产生并发送临时的随机对称密钥，通过更快的对称加密技术对其余的数据进行加密。

14.5 数字签名
除了加解密外，还可以用加密系统对报文进行签名(sign)，以说明是谁编写的报文，同时证明报文未被篡改过。这种技术被称为数字签名(digital signing)。

1. 签名是加了密的校验和
数字签名是附加在报文上的特殊加密校验码。
<1>签名可以证明是作者编写了这条报文。
只有作者才会有最机密的私有密钥，因此，只有作者才能计算出这些校验和。校验和就像来自作者的个人签名一样。
//这里假定私有密钥没有被偷走，大多数私有密钥都会在一段时间后过期。还有一些"取消列表"记录了被偷走或入侵的密钥。

<2>签名可以防止报文被篡改
如果有攻击者在报文传输过程中对其进行了修改，校验和就不再匹配了。

数字签名通常是用非对称公开密钥技术产生的。因此只有所有者才知道其私有密钥，所以可以将作者的私有密钥当做一种“指纹”使用。
- 节点A将变长报文提取为定长的摘要。
- 节点A对摘要应用了一个“签名”函数，这个函数会将用户的私有密钥作为参数。
- 一旦计算出签名，节点A就将其附加在报文的末尾，并将报文和签名都发送给B。
- 节点B使用公开密钥的反函数，如果拆包后的摘要与节点B自己的摘要版本不匹配。要么就是报文被篡改，要么就是发送端没有节点A的私有密钥(不是节点A)。
//这里的私有密钥，应该是用的混合加密系统中的对称密钥。

网上解释：
https://www.cnblogs.com/franson-2016/p/5530671.html
这里主要解释一下签名，签名就是在信息的后面再加上一段内容，可以证明信息没有被修改过，怎么样可以达到这个效果呢？
一般是对信息做一个hash计算得到一个hash值，注意，这个过程是不可逆的，也就是说无法通过hash值得出原来的信息内容。在把信息发送出去时，把这个hash值加密后做为一个签名和信息一起发出去。 接收方在收到信息后，会重新计算信息的hash值，并和信息所附带的hash值(解密后)进行对比，如果一致，就说明信息的内容没有被修改过，因为这里hash计算可以保证不同的内容一定会得到不同的hash值，所以只要内容一被修改，根据信息内容计算的hash值就会变化。当然，不怀好意的人也可以修改信息内容的同时也修改hash值，从而让它们可以相匹配，为了防止这种情况，hash值一般都会加密后(也就是签名)再和信息一起发送，以保证这个hash值不被修改。至于如何让别人可以解密这个签名，这个过程涉及到数字证书等概念，我们后面在说到数字证书时再详细说明，这里您先只需先理解签名的这个概念。

14.6 数字证书
数字证书中包含了由某个受信任组织担保的用户或公司的相关信息。

1. 证书的主要内容
对象的名称(人、服务器、组织等)
过期时间
证书发布者(谁为证书担保)
证书发布者的数字签名

数字证书通常还包括对象的公开密钥，以及对象和所用签名算法的描述性信息。

2. X.509 v3证书

3. 用证书对服务器进行认证
通过HTTPS建立一个安全Web事务之后，现代的浏览器都会自动获取所连接服务器的数字证书。如果服务器没有证书，安全连接就会失败。
<1>服务器证书包含很多字段：
- Web站点的名称和主机名
- Web站点的公开密钥
- 签名颁发机构的名称
- 来自签名颁发机构的签名

<2>浏览器收到证书时会对签名颁发机构进行检查。如果这个机构是个很权威的公共签名机构，浏览器可能已经知道其公开密钥(浏览器会预先安装很多签名颁发机构的证书)。这样浏览器就可以验证签名了。

<3>如果对签名颁发机构一无所知，浏览器就无法确定是否应该信任这个签名颁发机构，它通常会向用户显示一个对话框，看用户是否相信这个签名发布者。发布者可能是本地的IT部门或软件厂商。


第4章 连接管理
- HTTP是如何使用TCP连接的
- TCP连接的时延、瓶颈以及存在的障碍
- HTTP的优化，包括并行连接、keep-alive(持久连接)和管道化连接
- 管理连接时应该以及不应该做的事情

4.1 TCP连接
1. TCP的可靠数据管道
<1>TCP为HTTP提供了一条可靠的比特传输管道，从TCP连接一端填入的字节会从另一端以原有的顺序、正确地传送出来。
//要想正确、快速地发送数据，就需要了解TCP的一些基础知识。-- <<TCP/IP详解>>

2. TCP流是分段的、由IP分组传送
<1>TCP的数据是通过名为IP分组(或IP数据报)的小数据块来发送的。
- HTTP发送一条报文时，会以流的形式将报文数据的内容通过一条打开的TCP连接按序传输。
- TCP收到数据流之后，会将数据流砍成被称为段的小数据块，并将段封装在IP分组中，通过因特网进行传输。
所有的这些工作都是由TCP/IP软件来处理的，HTTP程序员感知不到。

3. 保持TCP连接的正确运行
<1>在任意时刻计算机都可以有几条TCP连接处于打开状态，TCP是通过端口号来保持所有这些连接的正确运行的。
源IP、源端口号、目的IP、目的端口号，这4个值一起唯一地定义了一条连接。

4. 用TCP套接字编程

4.2 对TCP性能的考虑
1. HTTP事务的时延
<1>与建立TCP连接、以及传输请求和响应报文的时间相比，事务处理时间可能是很短的。
//除非客户端或者服务器超载，或正在处理复杂的动态资源，否则HTTP时延就是由TCP网络时延构成的。

- 客户端首先需要根据URI确定Web服务器的IP地址和端口号。
//如果最近没有对URI中的主机名进行访问，通过DNS解析系统将URI中主机名转换成一个IP地址可能需要花费数十秒的时间。
- 客户端向服务器发送一条TCP连接请求，并等待服务器回送一个请求接受应答。
//每条新的TCP连接都会有连接建立时延，这个通常最多只有一两秒。但如果有数百个HTTP事务的话，这个值会快速地叠加上去。
- 一旦连接建立起来，客户端通过建立的TCP管道来发送HTTP请求。数据达到时，Web服务器会从TCP连接中读取请求报文，并对请求进行处理。因特网传输请求报文，以及服务器处理请求报文都需要时间。
- 然后，Web服务器会回送HTTP响应，这也需要花费时间。

2. 性能聚焦区域
- TCP连接建立握手
- TCP慢启动拥塞控制
- 数据聚集的Nagle算法
- 用于捎带确认的TCP延迟确认算法
- TIME_WAIT时延和端口耗尽

3. TCP连接的握手时延
<1>如果连接只用来传送少量数据，这些交换过程就会严重降低HTTP的性能。
小的HTTP事务可能会在TCP建立上花费50%，或更多的时间。
HTTP通过重用现存连接，来减少这种TCP建立时延所造成的影响。

4. 延迟确认
<1>由于因特网自身无法确保可靠的分组传输(因特网路由器超负荷的话，可以随意丢弃分组)，所以TCP实现了自己的确认机制来确保数据的成功传输。
- 每个TCP段都有一个序列号和数据完整性校验和。每个段的接收者收到完好的段时，都会向发送者回送小的确认分组。如果发送者没有在指定的窗口时间内收到确认信息，发送者就认为分组已经被破坏或者损毁，并重发数据。
//由于确认报文很小，所以TCP允许在发往相同方向的输出数据分组中对其进行“捎带”。可以更有效地利用网络。

<2>为了增加确认报文找到同乡传输数据分组的可能性，很多TCP栈都实现了一种“延迟算法”。延迟算法会在一个特定的窗口时间(100~200ms)内将输出确认存放在缓冲区中，以寻找能够捎带它的数据分组。
//如果那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送。

<3>但是HTTP具有双峰特性的请求-应答行为降低了捎带信息的可能。
通常延迟算法会引入相当大的时延。根据操作系统的不同，可以调整或禁止延迟确认算法。

5. TCP慢启动
<1>TCP数据传输的性能还取决于TCP连接的使用期(age)。
TCP连接会随着时间进行自我“调谐”，期初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐被称为TCP慢启动(slow start)，用于防止因特网的突然过载和拥塞。

<2>由于已协调连接要更快一些，所以HTTP中有一些可以重用现存连接的工具。

6. Nagle算法和TCP_NODELAY
<1>TCP有一个数据流端口，应用程序可以通过它将任意尺寸的数据放入TCP栈中(即使一次只放一个字节的数据)。
但是每个TCP段中都至少装载了40个字节的标记和首部，如果TCP发送了大量包含少量数据的分组，网络性能就会严重下降。

<2>Nagle算法试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。
Nagle算法鼓励发送全尺寸的段(LAN上最大尺寸的分组大约是1500字节，因特网上是几百字节)。
- 只有当所有其他分组都被确认后，Nagle算法才允许发送非全尺寸的分组。如果其他分组仍然在传输过程中，就将那部分数据缓存起来。只有当挂起分组被确认，或者缓存中积累了足够发送一个全尺寸分组的数据时，才会将缓存的数据发送出去。

<3>Nagle算法会引发几种HTTP的性能问题：
- 小的HTTP报文可能无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。
- Nagle算法与延迟确认之间的交互存在问题。
Nagle算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100-200ms。
//使用管道化连接时这些问题可能会更加严重。客户端可能会有多条报文要发送给同一个服务器，而且不希望有时延存在。

HTTP应用程序常常会在自己的栈中设置参数TCP_NODELAY，禁止Nagle算法，提高性能。
//这样做要确保向TCP写入大块的数据，这样就不会产生一堆小分组了。

7. TIME_WAIT累积与端口耗尽
<1>当某个TCP端口关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近关闭连接的IP地址和端口号。这类信息只会维持一小段时间，通常是所估计的最大分段使用期的2倍(2MSL，通常是2分钟)，以确保这段时间内不会创建具有相同地址和端口号的新连接。
//将2MSL(2倍的最大分段生存期)的值取为2分钟的原因：很久之前的路由器速度很慢，人们估计，在将一个分组的复制副本丢弃之前，它可以在因特网队列中保留最多一分钟。现在，最大分段生存期要小得多。

<2>有些操作系统会将2MSL设置为一个较小的值。
分组确实会被复制，如果来自之前连接的复制分组插入了具有相同连接值的新TCP流，会破坏TCP数据。

<3>即使没有遇到端口耗尽问题，在有大量打开连接或控制块的情况下，有些操作系统的速度会严重减缓。

4.3 HTTP连接的处理
1. 常被误解的connection首部
在某些情况下，两个相邻的HTTP应用程序会为它们共享的连接应用一组选项。
connection //通用首部，允许客户端和服务器指定与请求/响应连接有关的选项

<1>HTTP的connection首部字段中有一个由逗号分隔的连接标签列表，这些标签为此连接指定了一些不会传播到其他连接中去的选项。
//connection:close说明发送完下一条报文之后必须关闭的连接

<2>connection首部可以承载3中不同类型的标签：
- HTTP首部字段名，列出了只与此连接有关的首部
- 任意标签值，用于描述此连接的非标准选项
- 值close，说明操作完成之后需要关闭这条持久连接

<3>如果连接标签中包含了一个HTTP首部字段的名称，那么这个首部字段就包含了一些连接有关的信息，不能将其转发出去。
在将报文转发出去之前，必须删除Connection首部列出的所有首部字段。
//HTTP应用程序收到一条带有connection首部的报文时，接收端会解析发送端请求的所有选项，并将其应用。
然后会在将此报文转发给下一跳地址之前，删除connection首部以及connection中列出的所有首部。
而且可能还会有少量没有作为connection首部值列出，但一定不能被代理转发的逐跳首部，eg：
Proxy-Authenticate,Proxy-Connection,Transfer-Encoding,Upgrade等

<4>由于connection首部可以防止无意中对本地首部的转发，因此将逐跳首部名放入connection首部被称为“对首部的保护”。

2. 串行事务处理延迟
<1>如果只对连接进行简单的管理，TCP的性能延迟可能会叠加起来。
eg: 假设有一个包含了3个嵌入图片的Web页面。浏览器需要发起4个HTTP事务来显示此页面。
如果每个事务都要(串行地建立)一条新的连接，那么连接时延和慢启动时延就会叠加起来。
//处理串行加载引入的实际时延外，加载一幅图片时，页面上其他地方都没有动静也会让人觉得速度很慢。

<2>串行加载的另一个缺点是，有些浏览器在对象加载完毕之前无法获知对象的尺寸，而且它可能需要尺寸信息来决定将对象放在屏幕的什么位置上，所以在加载了足够多的对象之前，无法再屏幕上显示任何内容。
在这种情况下，可能浏览器串行装载对象的进度很正常，但用户面对的却是一个空白的屏幕，对装载的进度一无所知。
//HTML的设计者可以在图片等嵌入式对象的HTML标签中显示地添加宽度属性，以消除这种“布局时延”。

4.4 并行连接
HTTP允许客户端打开多条连接，并行地执行多个HTTP事务。
//嵌入的组件不一定都在同一台Web服务器上，可以同多台服务器建立并行的连接。

1. 并行连接可能会提高页面的加载速度
包含嵌入对象的组合页面如果能通过并行连接克服单条连接的空载时间和带宽限制，加载速度也会有所提高。

2. 并行连接不一定更快
<1>eg:带宽不足
//多条连接会产生一些额外的开销，使用并行连接装载整个页面所需的时间可能比串行下载的时间更长。

<2>打开大量连接会消耗很多内存资源，从而引发自身的性能问题。
//复杂的Web页面可能会有数十个或数百个内嵌对象。客户端可能可以打开数百个连接。但Web服务器通常要同时处理很多用户的请求，所以很少有Web服务器希望出现这样的情况。

<3>实际上浏览器却是使用了并行连接，但它们会将并行连接的总数限制为一个较小的值(通常是4)。
服务器可以随意关闭来自特定客户端的超量连接。

3. 并行连接可能让人“感觉”更快一些
渐进式图片会先显示低分辨了的近似图形，然后再逐渐增加图片的分辨率，而随着渐进式图片应用的逐步增加，这种效果就更加明显了。

4.5 持久连接
Web客户端经常会打开到同一站点的连接。因此，初始化了对某服务器HTTP请求的应用程序很可能会在不久的将来对那台服务器发起更多的请求。这种性质被称为站点本地性。

<1>HTTP/1.1允许HTTP是设备在事务处理结束后将TCP连接保持在打开状态，以便为未来的HTTP请求重用现存的连接。
在事务处理结束后仍然保持在打开状态的TCP连接被称为持久连接。

<2>非持久连接会在每个事务结束之后关闭；持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为止。

<3>重用已对目标服务器打开的空间持久连接，就可以避开缓慢的连接建立阶段。而且，已经打开的连接还可以避免慢启动的拥塞适应阶段。

1. 持久以及并行连接
<1>并行连接的缺点：
- 每个事务都会打开/关闭一条新的连接，会耗费时间和带宽
- 由于TCP慢启动特性的存在，每条新连接的性能都会有所降低
- 可打开的并行连接数量实际上是有限的

<2>持久连接降低了时延和连接建立的开销。将连接保持在已调谐状态，而且减少了打开连接的潜在数量。

<3>管理持久连接要特别注意，不然就会累积出大量的空闲连接，耗费本地以及远程客户端和服务器上的资源。

<4>持久连接和并行连接配合使用可能是最高效的方式。
很多Web引用程序都会打开少量的并行连接，并且每一条都是持久连接。

<5>持久连接有两种类型
HTTP/1.0+"keep-alive"
HTTP/1.1 "persistent"

2. HTTP/1.0+keep-alive连接

3. Keep-Alive操作
keep-alive已经不再使用，而且在当前的HTTP/1.1规范中也没有对它进行说明。但浏览器和服务器对keep-alive握手的使用仍然相当广泛。

<1>握手过程：
实现HTTP/1.0 keep-alive连接的客户端可以通过包含connection: Keep-Alive首部请求将一条连接保持在打开状态；
如果服务器愿意为下一条请求连接保持在打开状态，就在响应中包含相同的首部。
如果响应中没有connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。

4. Keep-Alive选项
<1>客户端和服务端可以在任意时刻关闭空闲的keep-alive连接，并可以随意限制keep-alive连接所处理事务的数量。

<2>可以用Keep-Alive通用首部中指定的、由逗号分隔的选项来调节keep-alive的行为。
- 参数timeout是在Keep-Alive响应首部发送的。它估计了服务器希望将连接保持在活跃状态的时间。并不是一个承诺值。
- 参数max是在Keep-Alive响应首部发送的。它估计了服务器还希望为多少个事务保持此连接的活跃状态。并不是一个承诺值。
- Keep-Alive首部还可以支持任意未经处理的属性，这些属性主要用于诊断和调试。name [=value]

<3>Keep-Alive首部完全是可选的，但只有在提供Connection: Keep-Alive时才能使用它。
eg：keep-alive响应首部的例子，说明服务器最多还会为另外5个事务保持连接的打开状态，或者将打开状态保持到连接空闲了2min之后。
Connection: Keep-Alive
Keep-Alive: max=5, timeout=120

5. Keep-Alive连接的限制和规则

6. Keep-Alive和哑代理
<1>Connection首部和盲中继
问题出现在那些不理解Connection首部，而且不知道在沿着转发链路将其发送出去之前，应该将该首部删除的代理。
很多老的或简单的代理都是盲中继(blind relay)，它们只是将字节从一个连接转发到另一个连接中去，不对Connection首部进行特殊处理。

eg: 假设有一个Web客户端正通过一个作为盲中继使用的哑代理与Web服务器进行对话：
- Web客户端向代理发送一条报文，其中包含了Connection:Keep-Alive
- 哑代理收到这条HTTP请求，但它并不理解Connection首部(只是将其作为扩展首部对待)。哑代理不知道Keep-Alive的意思，只是沿着转发链路将报文一字不漏地发送给服务器。
- Web服务器收到经过代理转发的Connection:Keep-Alive首部时，会误以为(对服务器来说，这个代理看起来就和所有其他客户端一样)希望进行Keep-Alive对话。服务器统一进行Keep-Alive对话，并回送了一个Connection:Keep-Alive响应首部。
- 哑代理将Web服务器的响应报文回送给客户端，并将来自Web服务器的Connection:Keep-Alive首部一起传送过去。
//此时，客户端和服务器都认为它们在进行Keep-Alive对话，但与它们进行对话的代理却一无所知。
//代理将收到的数据都回送给客户端，然后等待服务器关闭连接。但服务器认为代理已经请求将连接保持在打开状态，因此不会去关闭连接。这样，代理就会挂在那里等待连接的关闭。
- 客户端收到回送的响应报文时，会立即转向下一条请求，在Keep-Alive连接上向代理发送另一条请求。而代理并不认为同一条连接上会有其他请求到来，请求被忽略，浏览器就在这里转圈。

这种错误的通信方式会使浏览器一直处于挂起状态，直到客户端或服务器将连接超时，并将其关闭为止。

<2>代理和逐跳首部
为了避免此类代理通信问题的发生，现代的代理都绝不能转发Connection首部和所有名字出现在Connection值中的首部。

另外，还有几个不能作为Connection首部值列出，也不能被代理转发或作为缓存响应使用的首部：
Proxy-Authenticate, Proxy-Connection, Transfer-Encoding, Upgrade。

7. 插入Proxy-Connection

8. HTTP/1.1持久连接
HTTP/1.1逐渐停止了对Keep-Alive连接的支持，用一种名为持久连接(persistent connection)的改进型设计取代了它。
持久连接的目的与Keep-Alive连接相同，但工作机制更优一些。

<1>与Keep-Alive连接不同，HTTP/1.1持久连接在默认情况下是激活的。除非特别指明，否则HTTP/1.1假定所有连接都是持久的。
//要在事务处理结束之后将连接关闭，HTTP/1.1应用程序必须向报文中显示地添加一个Connection:close首部。

9. 持久连接的限制和规则

4.6 管道化连接
<1>HTTP/1.1允许在持久连接上可选地使用请求管道。这是在Keep-Alive连接上的进一步性能优化。
- 在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向服务器时，后面的请求也可以开始发送了。
//在高时延网络条件下，这样可以降低网络的环回时间，提高性能。

<2>几条限制：
- 如果HTTP客户端无法确认连接是持久的，就不应该使用管道。
- 必须按照与请求相同的顺序回送HTTP响应。
- HTTP客户端必须做好会在任意时刻关闭的准备，还要准备重发所有未完成的管道化请求。
- HTTP客户端不应该用管道化的方式发送会产生副作用的请求(如POST)。
//出错的时候，管道化方式会阻碍客户端了解服务器执行的是一系列管道化请求中的哪一些。由于无法安全地重试POST这样非幂等请求，出错时就存在某些方法永远不会被执行的风险。

4.7 关闭连接的奥秘
1. 任意解除连接
<1>所有HTTP客户端、服务器或代理都可以在任意时刻关闭一条TCP传输连接。
- 通常会在一条报文结束时关闭连接。
- 出错的时候，也可能在首部行的中间，或其他奇怪的地方关闭连接。
//除非服务器怀疑出现了客户端或网络故障，否则就不应该在请求的中间关闭连接。

<2>对管道化持久连接来说，这种情形时很常见的。
HTTP应用程序可以在经过任意一段时间之后关闭持久连接。但是服务器永远都无法确认在它关闭“空闲”连接的那一刻，在线路那一头的客户端有没有数据要发送。如果出现这种情况，客户端就会在写入半截请求报文时发现出现了连接错误。

2. Content-Length及截尾操作
<1>每条HTTP响应都应该有精确的Content-Length首部，用以描述响应主体的尺寸。
//一些老的HTTP服务器会省略Content-Length首部，或者包含错误的长度指示，这样就要依赖服务器发出的连接关闭来说明数据的真是末尾。

<2>如果接收端是个缓存代理，接收端就不应该缓存这条响应(以降低今后将潜在的错误报文混合起来的可能)。
代理应该将有问题的报文原封不动地转发出去，而不应该试图“校正”content-length，以维护语义的透明性。

3. 连接关闭容限、重试以及幂等性
<1>即使是在非错误的情况下，连接也可以在任意时刻关闭。HTTP应用程序要做好正确处理非预期关闭的准备。
如果客户端执行事务的过程中，传输连接关闭了，那么，除非事务处理会带来一些副作用，否则客户端就应该重新打开连接，并重试一次。

<2>副作用是很重要的问题。
有些事务，如GET一个静态的HTML页面，可以反复执行多次，也不会有什么变化；
有些事务，如向一个在线书店POST一张订单，就不能重复执行。

- 如果一个事务，不管是执行一次还是多次，得到的结果都是相同的，这样的事务就是幂等的。
//GET HEAD PUT DELETE TRACE OPTIONS方法都共享这一特性

- 客户端不应该以管道化方式传送非幂等请求(如POST)。要发送一条非幂等请求，就需要等待来自前一条请求的响应状态。

4. 正常关闭连接
TCP连接是双向的。TCP连接的每一端都有一个输入队列和一个输出队列，用于数据的读写。

<1>完全关闭和半关闭
应用程序可以关闭TCP输入和输出信道中的任意一个，或者将两者都关闭。
- 套接字close()将TCP连接的输入和输出信道都关闭。完全关闭
- 套接字shutdown()单独关闭输入或输出信道。半关闭

<2>TCP关闭及重置错误
- 使用半关闭防止对等实体收到非预期的写入错误：
关闭连接的输出信道总是很安全的。连接另一端的对等实体会在从其缓冲区中读出所有数据之后收到一条通知，说明流结束了，这样它就知道你将连接关闭了。

- 关闭连接的输入信道比较危险，除非你知道另一端不打算再发送其他数据。
如果对端向你已关闭的输入信道发送数据，操作系统就会向对端回送一条TCP"连接被对端重置"的报文。
//比如你已经在一条持久连接上发送了10条管道式请求，响应也已经收到，正在操作系统的缓冲区中存着(应用程序还未将其读走)。现在，假设你发送了第11条请求，但服务器认为你使用这条连接的时间已经够长了，并将其关闭。那么你的第11条请求就会被发送到一条已关闭的连接上去，并会向你回送一条重置信息。这个重置信息会清空你的输入缓冲区。当你最终要去读取数据的时候，就会得到一个连接被对端重置的错误，已缓存的未读响应数据都丢失了。

3. 正常关闭
<1>实现正常关闭的应用程序首先应该关闭它们的输出信道，然后等待连接另一端的对等实体关闭它的输出信道。
当两端都告诉对方它们不再发送任何数据(比如关闭输出信道)之后，连接就会被完全关闭，而不会有重置的危险。

<2>但无法确保对等实体会实现半关闭，或对其进行检查。因此，想要正常关闭连接的应用程序应该先半关闭其输出信道，然后周期性地检查其输入信道的状态(查找数据、或流的末尾)。
如果在一定的时间区间内对端没有关闭输入信道，应用程序可以强制关闭连接，以节省资源。


第5章 Web服务器
5.1 各种形状和尺寸的Web服务器
1. Web服务器的实现
