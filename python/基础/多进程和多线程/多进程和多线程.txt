一、多进程(multiprocessing)
1、Unix/Linux提供了fork()系统调用。
<1>fork()调用一次，返回两次。操作系统自动把当前进程(父进程)复制了一份(子进程)，然后分别在父进程和子进程内返回。
子进程中永远返回0，父进程中返回子进程的ID。
原因是：一个父进程可以fork出很多子进程，因此，父进程要记录下子进程的ID；而子进程只需要调用getppid()就可以得到父进程的ID。

<2>os模块封装了常见的系统调用，其中就包括fork。
print("Process %d start!" % os.getpid())
pid = os.fork()
if 0 == pid:
	print("I'm child process %d and my parent is %d." % (os.getpid(), os.getppid()))
else:
	print("I'm parent process %d and my child is %d." % (os.getpid(), pid));
	
<3>windows没有fork()系统调用；Mac下可以执行fork()。

<4>有了fork()调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务。
常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork子进程来处理新的http请求。

2、multiprocessing模块   //跨平台版本的多进程模块
multiprocessing模块提供了一个Process类来表示一个进程对象。

from multiprocessing import Process
import os

def run_proc(name):
    print('Run child process %s (%d)...' % (name, os.getpid()))

def main():
    print('Parent process %d.' % os.getpid())
    p = Process(target=run_proc,args=('test',))
    print('Child process will start.')
    p.start()
    p.join()
    print('Child process end.')

Process创建子进程时，需要传入一个执行函数和函数的参数。
process.start()方法启动子进程。
process.join()方法可以等待子进程结束后再继续往下执行(通常用于进程间的同步)。

3、Pool
如果要启动大量的子进程，可以用进程池的方式批量创建子进程。

<1>示例
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%d)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))


def main():
    print('Parent process %d.' % os.getpid())
    p = Pool(4)
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))

    print('Waiting for all subprocesses done...')
    p.close()
    p.join()
    print('All subprocesses done.')
	
执行结果：
[root@localhost test]# python multiprocess3.py 
Parent process 16959.
Waiting for all subprocesses done...
Run task 0 (16960)...
Run task 1 (16961)...
Run task 2 (16962)...
Run task 3 (16963)...
Task 3 runs 0.18 seconds.
Run task 4 (16963)...
Task 4 runs 0.18 seconds.
Task 1 runs 1.53 seconds.
Task 0 runs 1.60 seconds.
Task 2 runs 2.21 seconds.
All subprocesses done.

<2>代码解读
1)Pool.join()等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的process了。
2)task 0,1,2,3是立刻执行的，task 4则要等待前面某个task完成后才能执行。
这是因为Pool的大小设为了4，因此最多同时执行4个进程。
(如果不设置Pool大小，即p = Pool()，Pool的默认大小是CPU的核心数。)

4、子进程
很多时候，子进程并不是本身，而是一个外部进程。创建子进程后，还需要控制子进程的输入和输出。
subprocess模块可以非常方便地启动一个子进程，然后控制其输入和输出。

<1>示例
import subprocess

def main():
    print('$ ping 10.96.32.57 -c 4')
    r = subprocess.call(['ping', '10.96.32.57', '-c' , '4'])
    print('Exit code:', r)

执行结果：
[root@localhost test]# python multiprocess4.py     
$ ping 10.96.32.57 -c 4
PING 10.96.32.57 (10.96.32.57) 56(84) bytes of data.
64 bytes from 10.96.32.57: icmp_seq=1 ttl=59 time=1.30 ms
64 bytes from 10.96.32.57: icmp_seq=2 ttl=59 time=0.368 ms
64 bytes from 10.96.32.57: icmp_seq=3 ttl=59 time=0.392 ms
64 bytes from 10.96.32.57: icmp_seq=4 ttl=59 time=0.344 ms

--- 10.96.32.57 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3001ms
rtt min/avg/max/mdev = 0.344/0.602/1.307/0.408 ms
('Exit code:', 0)

6、进程间通讯
操作系统提供了很多机制实现进程间的通信，multiprocessing模块封装了底层的机制，提供了Queue、Pipes等多种方式交换数据。

以Queue为例：

from multiprocessing import Process, Queue
import os, time, random

# 写数据进程执行的代码:
def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pw结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()

执行结果：
Process to write: 50563
Put A to queue...
Process to read: 50564
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.


二、多线程
lock.acquire()
try:
    change_it(n)
finally:
   lock.release()
获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用try...finally来确保锁一定会被释放。