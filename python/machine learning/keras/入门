Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。
https://keras.io/	官网
http://keras-cn.readthedocs.io/en/latest/		中文文档

一. 快速开始
1. Keras的核心数据结构是“模型”，模型是一种组织网络层的方式。Keras中主要的模型是Sequential模型，Sequential是一系列网络层按顺序构成的栈。
from keras.models import Sequential
model = Sequential()

<1>将一些网络层通过.add()堆叠起来，就构成了一个模型：

from keras.layers import Dense, Activation

model.add(Dense(units=64, input_dim=100))
model.add(Activation("relu"))
model.add(Dense(units=10))
model.add(Activation("softmax"))

<2>使用.compile()方法来编译模型：
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])  //编译模型时必须指明损失函数和优化器

from keras.optimizers import SGD
model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))

<3>完成模型编译后，我们在训练数据上按batch进行一定次数的迭代来训练网络
model.fit(x_train, y_train, epochs=5, batch_size=32)

当然，我们也可以手动将一个个batch的数据送入网络中训练，这时候需要使用：
model.train_on_batch(x_batch, y_batch)

<4>随后，我们可以使用一行代码对我们的模型进行评估，看看模型的指标是否满足我们的要求：
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)

或者，我们可以使用我们的模型，对新的数据进行预测：
classes = model.predict(x_test, batch_size=128)

二、keras新手指南
1. 一些基本概念
<1>符号计算
- Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。
因此，这也使得Keras的编程与传统的Python代码有所差别。笼统的说，符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。
建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。

<2>张量(tensor)
- 张量可以看作是向量、矩阵的自然推广，我们用张量来表示广泛的数据类型。

规模最小的张量是0阶张量，即标量，也就是一个数。
把一些数有序的排列起来，就形成了1阶张量，也就是一个向量。
把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵。
把矩阵摞起来，就是3阶张量，我们可以称为一个立方体，具有3个颜色通道的彩色图片就是一个这样的立方体。
把立方体摞起来，就叫4阶张量了，不要去试图想像4阶张量是什么样子，它就是个数学上的概念。

- 张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。
譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量，沿着第1个轴你看到的是[1,3]，[2,4]两个向量。

a = np.array([[1,2],[3,4]])
sum0 = np.sum(a, axis=0)	// array([4, 6])
sum1 = np.sum(a, axis=1)	// array([3, 7])

<3>data_format
eg: 100张RGB三通道的16×32（高为16宽为32）彩色图表示:
theano:		channels_first(通道维靠前)		(100,3,16,32)
tensorflow: channels_last(通道维靠后)		(100,16,32,3)

Keras默认的数据组织形式在~/.keras/keras.json中规定，可查看该文件的image_data_format一项查看，
也可在代码中通过K.image_data_format()函数返回，请在网络的训练和测试中保持维度顺序一致。

<4>函数式模型
- 在Keras 0.x中，模型其实有两种。
第一种叫Sequential，称为序贯模型，也就是单输入单输出，一条路通到底，层与层之间只有相邻关系，跨层连接统统没有。这种模型编译速度快，操作上也比较简单。一种叫Sequential，称为序贯模型，也就是单输入单输出，一条路通到底，层与层之间只有相邻关系，跨层连接统统没有。这种模型编译速度快，操作上也比较简单。
第二种模型称为Graph，即图模型，这个模型支持多输入多输出，层与层之间想怎么连怎么连，但是编译速度慢。
可以看到，Sequential其实是Graph的一个特殊情况。

- 在Keras1和Keras2中，图模型被移除，而增加了了“functional model API”，这个东西，更加强调了Sequential是特殊情况这一点。
一般的模型就称为Model，然后如果你要用简单的Sequential，OK，那还有一个快捷方式Sequential。

- 由于functional model API在使用时利用的是“函数式编程”的风格，我们这里将其译为函数式模型。
总而言之，只要这个东西接收一个或一些张量作为输入，然后输出的也是一个或一些张量，那不管它是什么鬼，统统都称作“模型”。

<5>batch
- 深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式。
第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。
另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。
为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。

- 基本上现在的梯度下降都是基于mini-batch的，所以Keras的模块中经常会出现batch_size，就是指这个。
顺便说一句，Keras中用的优化器SGD是stochastic gradient descent的缩写，但不代表是一个样本就更新一回，还是基于mini-batch的。

<6>epochs
epochs指的就是训练过程中数据将被“轮”多少次，就这样。

epoch可译为“轮次”。如果说每个batch对应网络的一次更新的话，一个epoch对应的就是网络的一轮更新。每一轮更新中网络更新的次数可以随意，但通常会设置为遍历一遍数据集。因此一个epoch的含义是模型完整的看了一遍数据集。
设置epoch的主要作用是把模型的训练的整个训练过程分为若干个段，这样我们可以更好的观察和调整模型的训练。Keras中，当指定了验证集时，每个epoch执行完后都会运行一次验证集以确定模型的性能。
另外，我们可以使用回调函数在每个epoch的训练前后执行一些操作，如调整学习率，打印目前模型的一些信息等，详情请参考Callback一节。

//如果使用"批梯度下降"，每次遍历全部数据集算一次损失函数，此时会不会和epoch的定义有冲突???

<7>Sample
样本，数据集中的一条数据。例如图片数据集中的一张图片，语音数据中的一段音频。


2. FAQ
http://keras-cn.readthedocs.io/en/latest/for_beginners/FAQ/

<1>如何使Keras调用GPU?
<2>如何在多张GPU卡上使用Keras?
<3>"batch", "epoch"和"sample"都是啥意思？

<4>如何保存Keras模型?
- 使用model.save(filepath)将Keras模型和权重保存在一个HDF5文件中，该文件将包含：
	模型的结构，以便重构该模型
	模型的权重
	训练配置（损失函数，优化器等）
	优化器的状态，以便于从上次训练中断的地方开始
	
- 使用keras.models.load_model(filepath)来重新实例化你的模型，如果文件中存储了训练配置的话，该函数还会同时完成模型的编译。

- eg:
from keras.models import load_model

model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'
del model  				   # deletes the existing model

# returns a compiled model
# identical to the previous one
model = load_model('my_model.h5')

<5>为什么训练误差比测试误差高很多?
<6>如何获取中间层的输出?
<7>如何利用Keras处理超过机器内存的数据集?
<8>当验证集的loss不再下降时，如何中断训练?

<9>验证集是如何从训练集中分割出来的?
如果在model.fit中设置validation_spilt的值，则可将数据分为训练集和验证集，例如，设置该值为0.1，则训练集的最后10%数据将作为验证集，设置其他数字同理。
注意，原数据在进行验证集分割前并没有被shuffle，所以这里的验证集严格的就是你输入数据最末的x%。

<10>训练数据在训练时会被随机洗乱吗?
是的，如果model.fit的shuffle参数为真，训练的数据就会被随机洗乱。不设置时默认为真。训练数据会在每个epoch的训练中都重新洗乱一次。
验证集的数据不会被洗乱。

<11>如何在每个epoch后记录训练/测试的loss和正确率?
model.fit在运行结束后返回一个History对象，其中含有的history属性包含了训练过程中损失函数的值以及其他度量指标。
hist = model.fit(X, y, validation_split=0.2)
print(hist.history)

<12>如何使用状态RNN(stateful RNN)?
<13>如何“冻结”网络的层?
<14>如何从Sequential模型中去除一个层?
<15>如何在Keras中使用预训练的模型?
<16>如何在Keras中使用HDF5输入?
<17>Keras的配置文件存储在哪里?
<18>在使用Keras开发过程中，我如何获得可复现的结果?


-------------------------------------
训练输出：
loss: 	训练集的损失值
acc:	训练集的准确率
val_los: 验证集的损失值
val_acc: 验证集的准确率























